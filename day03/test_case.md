
# **User Story**  
## **Title:** Performance and Validation Testing for User Management API  

**As a** system administrator,  
**I want** to create, update, and delete users via the Reqres API,  
**So that** I can ensure that user data is processed correctly and the system performs well under load.  

---  

# **User Acceptance Criteria (UAC)**  

âœ… The system **must allow** creating a new user with a valid `name` and `job` fields.  
âœ… The system **must return** a valid `id` and `createdAt` timestamp upon successful user creation.  
âœ… The system **must allow** updating an existing userâ€™s `job` field.  
âœ… The system **must return** a `200 OK` response and update the user details correctly.  
âœ… The system **must allow** deleting an existing user and return a `204 No Content` response.  
âœ… API response times **must be under 1 second** for 95% of requests under normal load.  
âœ… No **500 Internal Server Errors** should occur during load testing.  

---  

# **Test Cases with Expected Results**  

## **1ï¸âƒ£ Functional Tests**  

| **Test Case ID** | **Description** | **Steps** | **Expected Result** |
|-----------------|----------------|-----------|---------------------|
| TC001 | Create a new user | 1. Send a `POST` request to `/api/users` with a valid `name` and `job`. | âœ… Response status = **201 Created** <br> âœ… Response contains a unique `id` <br> âœ… Response contains a valid `createdAt` timestamp |
| TC002 | Update user details | 1. Send a `PUT` request to `/api/users/{user_id}` with a new `job` value. | âœ… Response status = **200 OK** <br> âœ… `job` field is updated correctly |
| TC003 | Delete a user | 1. Send a `DELETE` request to `/api/users/{user_id}`. | âœ… Response status = **204 No Content** <br> âœ… User is removed successfully |

---  

## **2ï¸âƒ£ Performance Tests**  

### **ğŸš€ Load Test**  
âœ… Simulate **real-world traffic** with different numbers of users.  
âœ… Measure **response times (avg, min, max, p95, p99)**.  
âœ… Ensure **no request fails due to server overload**.  

| **Test Case ID** | **Description** | **Users** | **Expected Result** |
|-----------------|----------------|------------|---------------------|
| TC004 | Test with **10 concurrent users** | 10 | âœ… No errors, response time < 500ms |
| TC005 | Test with **100 concurrent users** | 100 | âœ… No request failures, response time < 1s |
| TC006 | Test with **500 concurrent users (stress test)** | 500 | ğŸš¨ Identify performance bottlenecks |

---  

### **ğŸ”¥ Spike Test**  
âœ… Simulate **sudden traffic spikes** (e.g., **Black Friday sales** scenario).  
âœ… Check if the system **recovers quickly** after a spike.  

| **Test Case ID** | **Description** | **Users** | **Expected Result** |
|-----------------|----------------|------------|---------------------|
| TC007 | **Suddenly increase users from 10 â†’ 500** in 5 sec | 10 â†’ 500 | âœ… System does not crash, handles traffic spike |
| TC008 | **Suddenly drop users from 500 â†’ 10** | 500 â†’ 10 | âœ… System recovers without errors |

---  

### **ğŸŒŠ Soak Test**  
âœ… Simulate continuous traffic over a long period.  
âœ… Detect **memory leaks** or **performance degradation**.  

| **Test Case ID** | **Description** | **Duration** | **Expected Result** |
|-----------------|----------------|-------------|---------------------|
| TC009 | **Run 100 users continuously for 1 hour** | 1 hour | âœ… System remains stable, no memory leaks |

---  

## **3ï¸âƒ£ How to Execute These Tests?**  
ğŸ’¡ **Follow this step-by-step execution plan:**  

1ï¸âƒ£ **Run a single-user test (`1 user`).**  
   ```sh
   locust -f day03\test_validateResponse.py --users 1 --spawn-rate 1 --headless
   ```  
   - **Check logs and ensure all operations work.**  
   - **Fix any issues before increasing load.**  

2ï¸âƒ£ **Increase users to `10`, then `50`, then `100`**  
   ```sh
   locust -f day03\test_validateResponse.py --users 10 --spawn-rate 2 --headless
   ```  
   - Monitor **response times, error rates, and logs**.  

3ï¸âƒ£ **Run a stress test (`500+ users`)**  
   ```sh
   locust -f day03\test_validateResponse.py --users 500 --spawn-rate 50 --headless
   ```  
   - Identify **system bottlenecks (database, API rate limits, etc.)**.  

4ï¸âƒ£ **Perform a spike test**  
   - Simulate **sudden high load** and check how the system reacts.  

5ï¸âƒ£ **Conduct a soak test**  
   - Run a **stable load for 1 hour** and check **memory usage, CPU load, and API stability**.  

---  

## **4ï¸âƒ£ Key Metrics to Monitor**  
While running the tests, focus on **these performance indicators**:  

| **Metric** | **What It Means** | **Ideal Value** |
|------------|------------------|----------------|
| **Response Time (Avg, P95, P99)** | How fast the API responds | P95 < 1s, P99 < 2s |
| **Error Rate** | Percentage of failed requests | **< 1%** |
| **Throughput (Req/sec)** | How many requests API handles per second | High as possible |
| **CPU & Memory Usage** | Server health check | Stay within limits |

---  

## **ğŸ¯ Conclusion**  
ğŸ”¹ Start small, analyze results, **increase load gradually**.  
ğŸ”¹ Use **different test types** (load, stress, spike, soak).  
ğŸ”¹ Monitor **key metrics** (response time, error rate, CPU usage).  
ğŸ”¹ **Optimize bottlenecks** before scaling up to real traffic.  

